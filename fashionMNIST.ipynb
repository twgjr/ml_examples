{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Getting Started Example\n",
    "Basic usage of the pytorch framework using the FashionMNIST dataset to classify images.  Some extra notes and code by me for clarity.\n",
    "https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download training and test data from open datasets.\n",
    "Pytorch comes with built-in popular datasets ready for trying out ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders\n",
    "Dataloaders set up the training data for training in randomized batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # number of examples per batch => 934 batches\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Actual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the Loss Functions and Optimizer for Training\n",
    "Fashion MNIST dataset has 9 classes.  Since this is a multiclass classification problem, we select cross entropy loss.  That gives each of the 9 classes a probability score that it is the correct class for the input fashion image.  Then choose the highest probability for prediction as the predicted class.\n",
    "\n",
    "Explanation of multiclass classification: https://machinelearningmastery.com/types-of-classification-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Training Loop with a Function\n",
    "This is where the model parameters are adjusted with gradient descent. The function performs one step of gradient descent for each training example within each batch defined in the Data Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Test Loop with a Function\n",
    "Model parameters are frozen, then the test input data is used to run predictions.  This is done to confirm the model can make accurate predictions on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training and Test Loops\n",
    "Epochs repeats the training and testing with the dataloaders. Here dataloaders were instantiated with the option ```shuffle=True```.  This allows the data to be randomly shuffled each epoch to increase diversity in training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "0\n",
      "loss: 2.312949  [    0/60000]\n",
      "100\n",
      "loss: 2.299469  [ 6400/60000]\n",
      "200\n",
      "loss: 2.276719  [12800/60000]\n",
      "300\n",
      "loss: 2.271442  [19200/60000]\n",
      "400\n",
      "loss: 2.259832  [25600/60000]\n",
      "500\n",
      "loss: 2.217210  [32000/60000]\n",
      "600\n",
      "loss: 2.234184  [38400/60000]\n",
      "700\n",
      "loss: 2.193502  [44800/60000]\n",
      "800\n",
      "loss: 2.198310  [51200/60000]\n",
      "900\n",
      "loss: 2.182774  [57600/60000]\n",
      "Test Error: Accuracy: 48.0%, Avg loss: 2.162542 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "0\n",
      "loss: 2.165981  [    0/60000]\n",
      "100\n",
      "loss: 2.162425  [ 6400/60000]\n",
      "200\n",
      "loss: 2.103024  [12800/60000]\n",
      "300\n",
      "loss: 2.125799  [19200/60000]\n",
      "400\n",
      "loss: 2.077706  [25600/60000]\n",
      "500\n",
      "loss: 2.009519  [32000/60000]\n",
      "600\n",
      "loss: 2.049284  [38400/60000]\n",
      "700\n",
      "loss: 1.963391  [44800/60000]\n",
      "800\n",
      "loss: 1.976336  [51200/60000]\n",
      "900\n",
      "loss: 1.929137  [57600/60000]\n",
      "Test Error: Accuracy: 55.9%, Avg loss: 1.903950 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "0\n",
      "loss: 1.924218  [    0/60000]\n",
      "100\n",
      "loss: 1.906695  [ 6400/60000]\n",
      "200\n",
      "loss: 1.784367  [12800/60000]\n",
      "300\n",
      "loss: 1.835256  [19200/60000]\n",
      "400\n",
      "loss: 1.721824  [25600/60000]\n",
      "500\n",
      "loss: 1.668146  [32000/60000]\n",
      "600\n",
      "loss: 1.702397  [38400/60000]\n",
      "700\n",
      "loss: 1.591612  [44800/60000]\n",
      "800\n",
      "loss: 1.623855  [51200/60000]\n",
      "900\n",
      "loss: 1.538798  [57600/60000]\n",
      "Test Error: Accuracy: 60.3%, Avg loss: 1.533734 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "0\n",
      "loss: 1.587340  [    0/60000]\n",
      "100\n",
      "loss: 1.564582  [ 6400/60000]\n",
      "200\n",
      "loss: 1.406259  [12800/60000]\n",
      "300\n",
      "loss: 1.486838  [19200/60000]\n",
      "400\n",
      "loss: 1.360793  [25600/60000]\n",
      "500\n",
      "loss: 1.354913  [32000/60000]\n",
      "600\n",
      "loss: 1.372318  [38400/60000]\n",
      "700\n",
      "loss: 1.289595  [44800/60000]\n",
      "800\n",
      "loss: 1.331303  [51200/60000]\n",
      "900\n",
      "loss: 1.240597  [57600/60000]\n",
      "Test Error: Accuracy: 63.2%, Avg loss: 1.258009 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "0\n",
      "loss: 1.327958  [    0/60000]\n",
      "100\n",
      "loss: 1.317726  [ 6400/60000]\n",
      "200\n",
      "loss: 1.147110  [12800/60000]\n",
      "300\n",
      "loss: 1.255337  [19200/60000]\n",
      "400\n",
      "loss: 1.131024  [25600/60000]\n",
      "500\n",
      "loss: 1.154456  [32000/60000]\n",
      "600\n",
      "loss: 1.174241  [38400/60000]\n",
      "700\n",
      "loss: 1.106936  [44800/60000]\n",
      "800\n",
      "loss: 1.152969  [51200/60000]\n",
      "900\n",
      "loss: 1.075391  [57600/60000]\n",
      "Test Error: Accuracy: 64.8%, Avg loss: 1.091500 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
